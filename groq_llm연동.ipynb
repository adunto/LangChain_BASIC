{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe2cf216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e80c9e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.\") , \n",
    "     (\"user\", \"{input}\")]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"JavaScriptëŠ” ë¬´ì—‡ì¸ê°€ìš”? ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9db56cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001F3C312DB80> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001F3C3536D20> root_client=<openai.OpenAI object at 0x000001F3C1D57890> root_async_client=<openai.AsyncOpenAI object at 0x000001F3C312DA90> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "# Groq APIë¥¼ ì‚¬ìš©í•˜ëŠ” ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02f69c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='JavaScriptëŠ” ì›¹ ê°œë°œì—ì„œ ë§ì´ ì‚¬ìš©ë˜ëŠ” í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤. ì´ ì–¸ì–´ëŠ” ì›¹ í˜ì´ì§€ì— ëŒ€í™”í˜• ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ê³  ë™ì  ì‚¬ìš©ì ê²½í—˜ì„ ì œê³µí•˜ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. JavaScriptëŠ” í´ë¼ì´ì–¸íŠ¸ ì¸¡ ìŠ¤í¬ë¦½íŒ… ì–¸ì–´ë¡œì„œ, ì„œë²„ê°€ ì•„ë‹Œ í´ë¼ì´ì–¸íŠ¸(ì‚¬ìš©ìì˜ ì›¹ ë¸Œë¼ìš°ì €)ì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.\\n\\n### ì—­ì‚¬\\nJavaScriptëŠ” 1995ë…„ ë„·ìŠ¤ì¼€ì´í”„(Netscape)ì—ì„œ ì²˜ìŒ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¹ì‹œì—ëŠ” ëª¨ì¹´(Mocha)ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ë¶ˆë ¸ìœ¼ë‚˜, ë‚˜ì¤‘ì— ìë°”ìŠ¤í¬ë¦½íŠ¸(JavaScript)ë¡œ ì´ë¦„ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì–¸ì–´ëŠ” ìë°”(Java)ì™€ëŠ” ë³„ê°œì˜ ì–¸ì–´ì´ë©°, ì´ë¦„ì˜ ìœ ì‚¬ì„±ì—ë„ ë¶ˆêµ¬í•˜ê³  ì§ì ‘ì ì¸ ê´€ë ¨ì€ ì—†ìŠµë‹ˆë‹¤.\\n\\n### íŠ¹ì§•\\n- **ë™ì  íƒ€ì´í•‘**: JavaScriptëŠ” ë™ì  íƒ€ì´í•‘ ì–¸ì–´ë¡œ, ë³€ìˆ˜ì˜ íƒ€ì…ì„ ì„ ì–¸í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ì´ëŠ” ê°œë°œì˜ ìœ ì—°ì„±ì„ ì œê³µí•˜ì§€ë§Œ, ë•Œë•Œë¡œ ì˜¤ë¥˜ë¥¼ ì´ˆë˜í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\\n- **ê°ì²´ ì§€í–¥ì **: ê°ì²´ ì§€í–¥ í”„ë¡œê·¸ë˜ë°(OOP) ê°œë…ì„ ì§€ì›í•©ë‹ˆë‹¤. ê°ì²´, ìƒì†, ë‹¤í˜•ì„± ë“±ì˜ ê¸°ëŠ¥ì„ í¬í•¨í•©ë‹ˆë‹¤.\\n- **í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë°**: ë³€ìˆ˜ì— í•¨ìˆ˜ë¥¼ í• ë‹¹í•  ìˆ˜ ìˆê³ , í•¨ìˆ˜ë¥¼ ì¸ìë¡œ ì „ë‹¬í•˜ê±°ë‚˜ ë°˜í™˜ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë°ì˜ íŠ¹ì§•ì…ë‹ˆë‹¤.\\n- **í´ë¼ì´ì–¸íŠ¸ ì¸¡ ì‹¤í–‰**: ì£¼ë¡œ ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ í´ë¼ì´ì–¸íŠ¸ ì¸¡ìœ¼ë¡œ ì‹¤í–‰ë˜ë©°, ì„œë²„ë¡œ ì „ì†¡ë˜ëŠ” ìš”ì²­ ì—†ì´ë„ ì‚¬ìš©ìì™€ì˜ ìƒí˜¸ì‘ìš©ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n### ì‚¬ìš© ë¶„ì•¼\\n- **ì›¹ ê°œë°œ**: ì›¹ì‚¬ì´íŠ¸ì— ëŒ€í™”í˜• ê¸°ëŠ¥, ì• ë‹ˆë©”ì´ì…˜, ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ë“±ì„ ì¶”ê°€í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤. \\n- **ëª¨ë°”ì¼ ì•± ê°œë°œ**: React Native, Angular Mobile ë“± í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•´ ëª¨ë°”ì¼ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì—ë„ ì‚¬ìš©ë©ë‹ˆë‹¤.\\n- **ì„œë²„ ì¸¡ ê°œë°œ**: Node.jsë¥¼ í†µí•´ ì„œë²„ ì¸¡ ê°œë°œë„ ê°€ëŠ¥í•©ë‹ˆë‹¤. Node.jsëŠ” JavaScriptë¥¼ ì„œë²„ ì¸¡ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ëŸ°íƒ€ì„ í™˜ê²½ì…ë‹ˆë‹¤.\\n- **ë°ìŠ¤í¬íƒ‘ ì• í”Œë¦¬ì¼€ì´ì…˜**: Electronê³¼ ê°™ì€ í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ìŠ¤í¬íƒ‘ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì—ë„ ì‚¬ìš©ë©ë‹ˆë‹¤.\\n\\n### ì£¼ìš” ê¸°ìˆ  ë° í”„ë ˆì„ì›Œí¬\\n- **React**: ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\\n- **Angular**: í”„ë ˆì„ì›Œí¬ë¡œ, ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ êµ¬ì¡°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\\n- **Vue.js**: ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ êµ¬ì¶•ì„ ìœ„í•œ ì ì§„ì  í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\\n- **Node.js**: JavaScriptë¥¼ ì„œë²„ ì¸¡ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ëŸ°íƒ€ì„ í™˜ê²½ì…ë‹ˆë‹¤.\\n\\n### ì¥ë‹¨ì \\n**ì¥ì **:\\n- í´ë¼ì´ì–¸íŠ¸ ì¸¡ì—ì„œ ì‹¤í–‰ë˜ì–´ ë¹ ë¥¸ ì‚¬ìš©ì ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.\\n- ë‹¤ì–‘í•œ í”„ë ˆì„ì›Œí¬ì™€ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì¡´ì¬í•˜ì—¬ ê°œë°œì„ ê°€ì†í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n- í¬ë¡œìŠ¤ í”Œë«í¼ ì§€ì›ì„ í†µí•´ ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ì‘ë™í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n**ë‹¨ì **:\\n- ë³´ì•ˆì— ì·¨ì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í´ë¼ì´ì–¸íŠ¸ ì¸¡ ì½”ë“œì´ë¯€ë¡œ ë³´ì•ˆ ë¯¼ê°í•œ ë¡œì§ì€ ì„œë²„ì—ì„œ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.\\n- ë¸Œë¼ìš°ì € ê°„ì˜ ì°¨ì´ë¡œ ì¸í•´ í˜¸í™˜ì„± ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n### ìš”ì•½\\nJavaScriptëŠ” ì›¹ ê°œë°œ, ëª¨ë°”ì¼ ì•± ê°œë°œ, ì„œë²„ ê°œë°œ, ë°ìŠ¤í¬íƒ‘ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ ë“±ì— ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ë‹¤ëª©ì  í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤. í´ë¼ì´ì–¸íŠ¸ ì¸¡ ìŠ¤í¬ë¦½íŒ…ì„ í†µí•´ ëŒ€í™”í˜• ì›¹ í˜ì´ì§€ë¥¼ ë§Œë“¤ê³ , ì„œë²„ ì¸¡ ê°œë°œì„ í†µí•´ ë°±ì—”ë“œ ë¡œì§ì„ ì²˜ë¦¬í•˜ëŠ” ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë©ë‹ˆë‹¤.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 664, 'prompt_tokens': 31, 'total_tokens': 695, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.212800177, 'prompt_time': 0.002790385, 'completion_time': 1.3576314, 'total_time': 1.360421785}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_79da0e0073', 'id': 'chatcmpl-b7f0e53d-0d2b-4167-abd5-e84a5339dc14', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--a9257888-9094-4fe2-a63e-aca210198c06-0' usage_metadata={'input_tokens': 31, 'output_tokens': 664, 'total_tokens': 695, 'input_token_details': {}, 'output_token_details': {}}\n",
      "ì‘ë‹µ: JavaScriptëŠ” ì›¹ ê°œë°œì—ì„œ ë§ì´ ì‚¬ìš©ë˜ëŠ” í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤. ì´ ì–¸ì–´ëŠ” ì›¹ í˜ì´ì§€ì— ëŒ€í™”í˜• ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ê³  ë™ì  ì‚¬ìš©ì ê²½í—˜ì„ ì œê³µí•˜ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. JavaScriptëŠ” í´ë¼ì´ì–¸íŠ¸ ì¸¡ ìŠ¤í¬ë¦½íŒ… ì–¸ì–´ë¡œì„œ, ì„œë²„ê°€ ì•„ë‹Œ í´ë¼ì´ì–¸íŠ¸(ì‚¬ìš©ìì˜ ì›¹ ë¸Œë¼ìš°ì €)ì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.\n",
      "\n",
      "### ì—­ì‚¬\n",
      "JavaScriptëŠ” 1995ë…„ ë„·ìŠ¤ì¼€ì´í”„(Netscape)ì—ì„œ ì²˜ìŒ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¹ì‹œì—ëŠ” ëª¨ì¹´(Mocha)ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ë¶ˆë ¸ìœ¼ë‚˜, ë‚˜ì¤‘ì— ìë°”ìŠ¤í¬ë¦½íŠ¸(JavaScript)ë¡œ ì´ë¦„ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì–¸ì–´ëŠ” ìë°”(Java)ì™€ëŠ” ë³„ê°œì˜ ì–¸ì–´ì´ë©°, ì´ë¦„ì˜ ìœ ì‚¬ì„±ì—ë„ ë¶ˆêµ¬í•˜ê³  ì§ì ‘ì ì¸ ê´€ë ¨ì€ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "### íŠ¹ì§•\n",
      "- **ë™ì  íƒ€ì´í•‘**: JavaScriptëŠ” ë™ì  íƒ€ì´í•‘ ì–¸ì–´ë¡œ, ë³€ìˆ˜ì˜ íƒ€ì…ì„ ì„ ì–¸í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ì´ëŠ” ê°œë°œì˜ ìœ ì—°ì„±ì„ ì œê³µí•˜ì§€ë§Œ, ë•Œë•Œë¡œ ì˜¤ë¥˜ë¥¼ ì´ˆë˜í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
      "- **ê°ì²´ ì§€í–¥ì **: ê°ì²´ ì§€í–¥ í”„ë¡œê·¸ë˜ë°(OOP) ê°œë…ì„ ì§€ì›í•©ë‹ˆë‹¤. ê°ì²´, ìƒì†, ë‹¤í˜•ì„± ë“±ì˜ ê¸°ëŠ¥ì„ í¬í•¨í•©ë‹ˆë‹¤.\n",
      "- **í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë°**: ë³€ìˆ˜ì— í•¨ìˆ˜ë¥¼ í• ë‹¹í•  ìˆ˜ ìˆê³ , í•¨ìˆ˜ë¥¼ ì¸ìë¡œ ì „ë‹¬í•˜ê±°ë‚˜ ë°˜í™˜ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë°ì˜ íŠ¹ì§•ì…ë‹ˆë‹¤.\n",
      "- **í´ë¼ì´ì–¸íŠ¸ ì¸¡ ì‹¤í–‰**: ì£¼ë¡œ ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ í´ë¼ì´ì–¸íŠ¸ ì¸¡ìœ¼ë¡œ ì‹¤í–‰ë˜ë©°, ì„œë²„ë¡œ ì „ì†¡ë˜ëŠ” ìš”ì²­ ì—†ì´ë„ ì‚¬ìš©ìì™€ì˜ ìƒí˜¸ì‘ìš©ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### ì‚¬ìš© ë¶„ì•¼\n",
      "- **ì›¹ ê°œë°œ**: ì›¹ì‚¬ì´íŠ¸ì— ëŒ€í™”í˜• ê¸°ëŠ¥, ì• ë‹ˆë©”ì´ì…˜, ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ë“±ì„ ì¶”ê°€í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤. \n",
      "- **ëª¨ë°”ì¼ ì•± ê°œë°œ**: React Native, Angular Mobile ë“± í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•´ ëª¨ë°”ì¼ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì—ë„ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
      "- **ì„œë²„ ì¸¡ ê°œë°œ**: Node.jsë¥¼ í†µí•´ ì„œë²„ ì¸¡ ê°œë°œë„ ê°€ëŠ¥í•©ë‹ˆë‹¤. Node.jsëŠ” JavaScriptë¥¼ ì„œë²„ ì¸¡ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ëŸ°íƒ€ì„ í™˜ê²½ì…ë‹ˆë‹¤.\n",
      "- **ë°ìŠ¤í¬íƒ‘ ì• í”Œë¦¬ì¼€ì´ì…˜**: Electronê³¼ ê°™ì€ í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ìŠ¤í¬íƒ‘ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì—ë„ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
      "\n",
      "### ì£¼ìš” ê¸°ìˆ  ë° í”„ë ˆì„ì›Œí¬\n",
      "- **React**: ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\n",
      "- **Angular**: í”„ë ˆì„ì›Œí¬ë¡œ, ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ êµ¬ì¡°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
      "- **Vue.js**: ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ êµ¬ì¶•ì„ ìœ„í•œ ì ì§„ì  í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
      "- **Node.js**: JavaScriptë¥¼ ì„œë²„ ì¸¡ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ëŸ°íƒ€ì„ í™˜ê²½ì…ë‹ˆë‹¤.\n",
      "\n",
      "### ì¥ë‹¨ì \n",
      "**ì¥ì **:\n",
      "- í´ë¼ì´ì–¸íŠ¸ ì¸¡ì—ì„œ ì‹¤í–‰ë˜ì–´ ë¹ ë¥¸ ì‚¬ìš©ì ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "- ë‹¤ì–‘í•œ í”„ë ˆì„ì›Œí¬ì™€ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì¡´ì¬í•˜ì—¬ ê°œë°œì„ ê°€ì†í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "- í¬ë¡œìŠ¤ í”Œë«í¼ ì§€ì›ì„ í†µí•´ ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ì‘ë™í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "**ë‹¨ì **:\n",
      "- ë³´ì•ˆì— ì·¨ì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í´ë¼ì´ì–¸íŠ¸ ì¸¡ ì½”ë“œì´ë¯€ë¡œ ë³´ì•ˆ ë¯¼ê°í•œ ë¡œì§ì€ ì„œë²„ì—ì„œ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "- ë¸Œë¼ìš°ì € ê°„ì˜ ì°¨ì´ë¡œ ì¸í•´ í˜¸í™˜ì„± ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### ìš”ì•½\n",
      "JavaScriptëŠ” ì›¹ ê°œë°œ, ëª¨ë°”ì¼ ì•± ê°œë°œ, ì„œë²„ ê°œë°œ, ë°ìŠ¤í¬íƒ‘ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ ë“±ì— ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ë‹¤ëª©ì  í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤. í´ë¼ì´ì–¸íŠ¸ ì¸¡ ìŠ¤í¬ë¦½íŒ…ì„ í†µí•´ ëŒ€í™”í˜• ì›¹ í˜ì´ì§€ë¥¼ ë§Œë“¤ê³ , ì„œë²„ ì¸¡ ê°œë°œì„ í†µí•´ ë°±ì—”ë“œ ë¡œì§ì„ ì²˜ë¦¬í•˜ëŠ” ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(response)\n",
    "    print(\"ì‘ë‹µ:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9444d0a",
   "metadata": {},
   "source": [
    "### LCEL (Prompt + LLMëª¨ë¸)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d707a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='You are an expert in AI Expert. Answer the question. <Question>: {input}ì— ëŒ€í•´ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}ì— ëŒ€í•´ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88c42edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ëŠ” ì‚¬ëŒì˜ ë‡Œê°€ í•™ìŠµí•˜ëŠ” ì›ë¦¬ì™€ ìœ ì‚¬í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ë‡ŒëŠ” ê²½í—˜ì„ í†µí•´ ë°°ìš°ê³ , ìƒˆë¡œìš´ ì •ë³´ë¥¼ ê¸°ì¡´ ì§€ì‹ê³¼ ì—°ê²°í•˜ì—¬ ì´í•´í•©ë‹ˆë‹¤. ì¸ê³µì§€ëŠ¥ ëª¨ë¸ë„ ë°ì´í„°ë¥¼ í†µí•´ ë°°ìš°ê³ , ê·¸ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ íŒ¨í„´ì„ ì°¾ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡ì´ë‚˜ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
      "\n",
      "ë³´ë‹¤ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ë©´, ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ë°ì´í„° ìˆ˜ì§‘**: ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´ì„œëŠ”å¤§é‡çš„ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ ë°ì´í„°ëŠ” ë¬¸ì œì— ëŒ€í•œ ë‹µì„ í¬í•¨í•˜ê³  ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **ë°ì´í„° ì „ì²˜ë¦¬**: ìˆ˜ì§‘ëœ ë°ì´í„°ëŠ” ëª¨ë¸ì— ì…ë ¥í•˜ê¸° ì „ì— ì „ì²˜ë¦¬ ê³¼ì •ì„ ê±°ì¹©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œëŠ” ë°ì´í„°ì˜ í’ˆì§ˆì„ ë†’ì´ê³ , ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ë©°, ë°ì´í„°ë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ëª¨ë¸ ì„ íƒ**: ì í•©í•œ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ ì„ íƒí•©ë‹ˆë‹¤. ëª¨ë¸ì˜ ì¢…ë¥˜ì—ëŠ” ì‹ ê²½ë§, ê²°ì • íŠ¸ë¦¬, ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  ë“± ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆìœ¼ë©°, ë¬¸ì œì˜ ì„±ê²©ì— ë”°ë¼ ì ì ˆí•œ ëª¨ë¸ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "4. **í•™ìŠµ**: ì„ íƒëœ ëª¨ë¸ì— ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì…ë ¥í•˜ì—¬ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ ëª¨ë¸ì€ ë°ì´í„°ì˜ íŒ¨í„´ì„ ë¶„ì„í•˜ê³ , ì´ë¥¼ í†µí•´ ì˜ˆì¸¡ì´ë‚˜ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n",
      "\n",
      "5. **í‰ê°€**: í•™ìŠµì´ ì™„ë£Œëœ í›„, ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ì„œëŠ” ë³„ë„ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ë©°, ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ì™€ ì‹¤ì œ ê°’ì„ ë¹„êµí•˜ì—¬ ì •í™•ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
      "\n",
      "6. **íŠœë‹**: ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ë§Œì¡±ìŠ¤ëŸ½ì§€ ì•Šì€ ê²½ìš°, ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ê±°ë‚˜ í•™ìŠµ ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ëŠ” ë“±ì˜ ë°©ë²•ì„ í†µí•´ ëª¨ë¸ì„ ê°œì„ í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´, ê³ ì–‘ì´ì™€ ê°œ ì‚¬ì§„ì„ ë¶„ë¥˜í•˜ëŠ” ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ ë§Œë“ ë‹¤ê³  ê°€ì •í•´ ë´…ì‹œë‹¤. ì´ë¥¼ ìœ„í•´ ìš°ë¦¬ëŠ”å¤§é‡çš„ ê³ ì–‘ì´ì™€ ê°œ ì‚¬ì§„ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³ , ì´ë¥¼ í†µí•´ ëª¨ë¸ì´ ê³ ì–‘ì´ì™€ ê°œì˜ íŠ¹ì§•ì„ í•™ìŠµí•˜ë„ë¡ í•©ë‹ˆë‹¤. ëª¨ë¸ì€ ì´ ë°ì´í„°ë¥¼ í†µí•´ ê³ ì–‘ì´ëŠ” ê·€ê°€ í¬ê³ , ëˆˆì´ í¬ë©°, í„¸ì´ ë³´ë“œë¼ìš´ íŠ¹ì§•ì´ ìˆê³ , ê°œëŠ” ê·€ê°€ ì‘ê³ , ê¼¬ë¦¬ê°€ ê¸´ íŠ¹ì§•ì´ ìˆë‹¤ëŠ” ê²ƒì„ í•™ìŠµí•©ë‹ˆë‹¤. ì´í›„ ìƒˆë¡œìš´ ì‚¬ì§„ì„ ì…ë ¥í•˜ë©´, ëª¨ë¸ì€ ì´ë¥¼ ë¶„ì„í•˜ì—¬ ê³ ì–‘ì´ì¸ì§€ ê°œì¸ì§€ ë¶„ë¥˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ì²˜ëŸ¼ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì€ ë°ì´í„°ë¥¼ í†µí•´ ë°°ìš°ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡ì´ë‚˜ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì€ ì‚¬ëŒì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ì—¬ ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain ì—°ê²° (LCEL)\n",
    "chain = prompt | llm\n",
    "\n",
    "# chain í˜¸ì¶œ\n",
    "result = chain.invoke({\"input\": \"ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬\"})\n",
    "print(type(result))\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c84345",
   "metadata": {},
   "source": [
    "### LLM ì²´ì¸\n",
    "- ( Prompt + LLM ëª¨ë¸ + ì¶œë ¥íŒŒì„œ) - LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf639d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='You are an expert in AI Expert. Answer the question. <Question>: {input}ì— ëŒ€í•´ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"You are an expert in AI Expert. Answer the question. <Question>: {input}ì— ëŒ€í•´ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811b05d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d34d0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. chain ìƒì„± (LCEL)\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feec22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<Answer>:\n",
      "ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµì›ë¦¬ëŠ” ë°ì´í„°ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ì¼ë ¨ì˜ ê³„ì‚°ì„ í†µí•´ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ëª¨ë¸ì€ ì…ë ¥ ë°ì´í„°ì™€ ì •ë‹µ ë°ì´í„° ì‚¬ì´ì˜ ê´€ê³„ë¥¼ í•™ìŠµí•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ ì˜ˆì¸¡ì„ í•  ìˆ˜ ìˆë„ë¡ í•™ìŠµë©ë‹ˆë‹¤. í•™ìŠµ ê³¼ì •ì—ì„œ ëª¨ë¸ì€ ì˜¤ì°¨ë¥¼ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•˜ë©°, ì´ë¥¼ í†µí•´ ë°ì´í„° ê°„ì˜ íŒ¨í„´ê³¼ ê´€ë ¨ì„±ì„ íŒŒì•…í•˜ê²Œ ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ í•™ìŠµê³¼ì •ì„ í†µí•´ ëª¨ë¸ì€ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ë³´ë‹¤ ì •í™•í•˜ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# 3. chainì˜ invoke í˜¸ì¶œ\n",
    "result = chain.invoke({\"input\": \"ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf85923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "LangChainì€ ë‹¤ì–‘í•œ AI ê¸°ìˆ ê³¼ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ê¸°ì—…ì…ë‹ˆë‹¤. LangChainì˜ ì œí’ˆì—ëŠ” ë‹¤êµ­ì–´ ë²ˆì—­ ë° í†µì—­ ì†”ë£¨ì…˜, ìì—°ì–´ ì²˜ë¦¬ ê¸°ìˆ ì„ í™œìš©í•œ ì±—ë´‡ ë° ê°€ìƒ ë¹„ì„œ ì„œë¹„ìŠ¤, ì–¸ì–´ í•™ìŠµ ë° êµìœ¡ í”Œë«í¼ ë“±ì´ ìˆìŠµë‹ˆë‹¤. ë˜í•œ LangChainì€ ê³ ê°ì˜ ìš”êµ¬ì— ë§ëŠ” ë§ì¶¤í˜• AI ì†”ë£¨ì…˜ì„ ê°œë°œí•˜ì—¬ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    result = chain.invoke({\"input\": \"LangChainì˜ Products(ì œí’ˆ)ëŠ” ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?\"})\n",
    "    print(type(result))\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0fa10b",
   "metadata": {},
   "source": [
    "### Runnableì˜ stream() í•¨ìˆ˜ í˜¸ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceac380f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object RunnableSequence.stream at 0x000001F30CB5F2E0>\n",
      "ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ ì‰½ê²Œ ì„¤ëª…í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì€ ë°ì´í„°ë¥¼ ì…ë ¥ë°›ì•„ í•™ìŠµì„ í•˜ê³ , ê·¸ ë°ì´í„°ì—ì„œ íŒ¨í„´ì„ ì°¾ì•„ë‚´ì–´ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì˜ˆì¸¡í•˜ê±°ë‚˜ ë¶„ë¥˜í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì€ í¬ê²Œ ì…ë ¥ ë°ì´í„°ë¥¼ ë°›ì•„ë“¤ì´ê³ , ì´ë¥¼ ê°€ê³µí•˜ì—¬ ì¶œë ¥í•˜ëŠ” ê³¼ì •ìœ¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "í•™ìŠµ ê³¼ì •ì€ ì…ë ¥ ë°ì´í„°ë¥¼ ëª¨ë¸ì— ì£¼ì…í•˜ê³ , ëª¨ë¸ì´ ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì¼ì •í•œ íŒ¨í„´ì´ë‚˜ íŠ¹ì§•ì„ í•™ìŠµí•©ë‹ˆë‹¤. ì´ë•Œ ëª¨ë¸ì€ ì‚¬ì „ì— ì •ì˜ëœ ëª©í‘œì— ë§ê²Œ ìµœì í™”ë˜ëŠ”ë°, ì´ê²ƒì„ ì–´ë–¤ ê¸°ì¤€ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸¡ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ëª¨ë¸ì´ í•™ìŠµì„ í†µí•´ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ê±°ë‚˜ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ” ì´ìœ ëŠ” ì´ë ‡ê²Œ í•™ìŠµëœ íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.ë”°ë¼ì„œ, ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•µì‹¬ì€ ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ íŒ¨í„´ì„ ì°¾ì•„ë‚´ëŠ” ê²ƒì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
     ]
    }
   ],
   "source": [
    "# ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ìœ„í•œ ìš”ì²­\n",
    "try:\n",
    "    answer = chain.stream({\"input\": \"ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ ìì„¸í•˜ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\"})\n",
    "    # ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
    "    print(answer)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "for token in answer:\n",
    "    # ìŠ¤íŠ¸ë¦¼ì—ì„œ ë°›ì€ ë°ì´í„°ì˜ ë‚´ìš©ì„ ì¶œë ¥í•©ë‹ˆë‹¤. ì¤„ë°”ê¿ˆ ì—†ì´ ì´ì–´ì„œ ì¶œë ¥í•˜ê³ , ë²„í¼ë¥¼ ì¦‰ì‹œ ë¹„ì›ë‹ˆë‹¤.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8080a1",
   "metadata": {},
   "source": [
    "### Multi Chain\n",
    "* ì²« ë²ˆì§¸ Chainì˜ ì¶œë ¥ì´, ë‘ ë²ˆì§¸ Chainì˜ ì…ë ¥ì´ ëœë‹¤.\n",
    "* ë‘ ê°œì˜ Chainê³¼ Prompt + OutputParserë¥¼ LCELë¡œ ì—°ê²°í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc8c973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¥ë¥´ì— ë”°ë¼ ì˜í™” ì¶”ì²œ\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} ì¥ë¥´ì—ì„œ ì¶”ì²œí•  ë§Œí•œ ì˜í™”ë¥¼ í•œ í¸ ì•Œë ¤ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# Step 2: ì¶”ì²œëœ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ ìš”ì•½\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} ì¶”ì „í•œ ì˜í™”ì˜ ì œëª©ì„ ë¨¼ì € ì•Œë ¤ì£¼ì‹œê³ , ì¤„ì„ ë°”ê¾¸ì–´ì„œ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ 7ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì‚¬ìš©\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# ì²´ì¸ 1: ì˜í™” ì¶”ì²œ (ì…ë ¥: ì¥ë¥´ â†’ ì¶œë ¥: ì˜í™” ì œëª©)\n",
    "chain1 = prompt1 | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db19765b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ë§¤ë“œ ë§¥ìŠ¤: ë¶„ë…¸ì˜ ë„ë¡œ'\n",
      "\n",
      "- ì¤„ê±°ë¦¬ ìš”ì•½ -\n",
      "\n",
      "ë§¥ìŠ¤ëŠ” í¬ìŠ¤íŠ¸ ì•„í¬ì¹¼ë¦½ìŠ¤ ì„¸ê³„ì—ì„œ ìì‹ ì˜ ì°¨ë¥¼ ë¹¼ì•—ê¸´ ì•…ë‹¹ë“¤ê³¼ì˜ ì „íˆ¬ ì†ì—ì„œ ë¯¸ì¹œ ë“¯ì´ ë‹¬ë¦¬ë©° ì«“ê¸°ê²Œ ëœë‹¤. ê·¸ë¦¬ê³  ê·¸ëŠ” ë¬´ëª¨í•œ ì—¬ì„± ì „ì‚¬ì¸ í¼ë¦¬ì˜¤ì‚¬ì™€ ë§Œë‚˜ í•¨ê»˜ ì•…ë‹¹ë“¤ì„ ìƒëŒ€ë¡œ ì‚¬ìƒ ìµœì•…ì˜ ì „íˆ¬ë¥¼ ë²Œì´ê²Œ ëœë‹¤. ë§¥ìŠ¤ëŠ” ë¬¼ìê°€ ë¶€ì¡±í•œ ì„¸ìƒì—ì„œ ì‚´ì•„ê°€ê¸° ìœ„í•´ ë¶ˆíƒ€ëŠ” ì†Œëª©ì— ì§ë©´í•˜ê²Œ ë˜ì§€ë§Œ, ê·¸ëŠ” ìì‹ ì˜ ìš©ê¸°ì™€ ì „íˆ¬ë ¥ìœ¼ë¡œ ì–´ë ¤ì›€ì„ ê·¹ë³µí•´ ë‚˜ê°€ë©° í¬ìŠ¤íŠ¸ ì•„í¬ì¹¼ë¦½ìŠ¤ ì„¸ê³„ì—ì„œ ì‚´ì•„ë‚¨ê¸° ìœ„í•œ ëª¨í—˜ì„ ë– ë‚œë‹¤. í¼ë¦¬ì˜¤ì‚¬ì™€ í•¨ê»˜í•œ ë§¥ìŠ¤ëŠ” ì•…ë‹¹ë“¤ê³¼ì˜ ì¹˜ì—´í•œ ì‹¸ì›€ ì†ì—ì„œ ì‚¶ê³¼ ì£½ìŒì„ ê±´ ê²°ì „ì„ í¼ì¹˜ê²Œ ë˜ëŠ”ë°, ê·¸ ê³¼ì •ì—ì„œ ë§¥ìŠ¤ëŠ” ë‚´ë©´ì˜ ë¶„ë…¸ì™€ ìš•ë§, ê·¸ë¦¬ê³  ì†Œë§ê³¼ í¬ë§ì„ ë§ˆì£¼í•˜ê²Œ ë˜ëŠ”ë°...\n"
     ]
    }
   ],
   "source": [
    "# ì²´ì¸ 2: ì¤„ê±°ë¦¬ ìš”ì•½ (ì…ë ¥: ì˜í™” ì œëª© â†’ ì¶œë ¥: ì¤„ê±°ë¦¬)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1ì˜ ì¶œë ¥ì„ movie ë³€ìˆ˜ë¡œ ì „ë‹¬\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ì‹¤í–‰: \"SF\" ì¥ë¥´ì˜ ì˜í™” ì¶”ì²œ ë° ì¤„ê±°ë¦¬ ìš”ì•½\n",
    "response = chain2.invoke({\"genre\": \"ì•¡ì…˜\"})\n",
    "print(response)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836b41de",
   "metadata": {},
   "source": [
    "### PromptTemplate ì—¬ëŸ¬ê°œ ì—°ê²°í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406b8e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_text = \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# PromptTemplate ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# í…œí”Œë¦¿ì— ê°’ì„ ì±„ì›Œì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ì™„ì„±\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# ë¬¸ìì—´ í…œí”Œë¦¿ ê²°í•© (PromptTemplate + PromptTemplate + ë¬¸ìì—´)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n ê·¸ë¦¬ê³  {model_name} ëª¨ë¸ì˜ ì¥ì ì„ ìš”ì•½ ì •ë¦¬í•´ ì£¼ì„¸ìš”\")\n",
    "              + \"\\n\\n {model_name} ëª¨ë¸ê³¼ ë¹„ìŠ·í•œ AI ëª¨ë¸ì€ ì–´ë–¤ ê²ƒì´ ìˆë‚˜ìš”? ëª¨ë¸ëª…ì€ {language}ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"ì˜ì–´\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"ì˜ì–´\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf05014",
   "metadata": {},
   "source": [
    "### ì—¬ëŸ¬ê°œì˜ PromptTemplate ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105998cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 2 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.', 'Gemma ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 3 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.']\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# PromptTemplate ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 2},\n",
    "    {\"model_name\": \"Gemma\", \"count\": 3},\n",
    "]\n",
    "\n",
    "# ì—¬ëŸ¬ ê°œì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë¯¸ë¦¬ ìƒì„±\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # ë¯¸ë¦¬ ìƒì„±ëœ ì§ˆë¬¸ ëª©ë¡ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd5eeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='GPT-4 ëª¨ë¸ì€ ëŒ€ê·œëª¨ì˜ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ìê¸° ì§€ë„ í•™ìŠµ ë°©ì‹ìœ¼ë¡œ ì‚¬ì „ í›ˆë ¨ë˜ë©°, í…ìŠ¤íŠ¸ì˜ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê³¼ì •ì„ í†µí•´ ë¬¸ë§¥ì„ ì´í•´í•˜ê³  ìƒì„±í•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ì—„ì²­ë‚œ ì–‘ì˜ ë§¤ê°œë³€ìˆ˜ì™€ ê³„ì‚° ëŠ¥ë ¥ì„ ê°€ì§€ê³  ìˆì–´ ìì—°ì–´ ì²˜ë¦¬ ì‘ì—…ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 40, 'total_tokens': 172, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BgnWMYdOyniIK1zt4Q7RMrjJXUZCH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--3df5e478-3a58-4cdf-8a18-4a4e88ae1a13-0' usage_metadata={'input_tokens': 40, 'output_tokens': 132, 'total_tokens': 172, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content='Gemma ëª¨ë¸ì€ ì „ì´ í•™ìŠµì„ í†µí•´ ê¸°ì¡´ì˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì— ëŒ€í•œ í•™ìŠµ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. Gemma ëª¨ë¸ì€ í•™ìŠµëœ ì •ë³´ë¥¼ ì €ì¥í•˜ê³  ì¼ì • ê¸°ê°„ ì´ë¥¼ ë³´ì¡´í•˜ì—¬ í•™ìŠµ ì‹œê°„ì„ ë‹¨ì¶•ì‹œí‚¤ë©°, ìƒˆë¡œìš´ ë°ì´í„°ì— ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Gemma ëª¨ë¸ì€ ê°•í™” í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ê°€ í™˜ê²½ê³¼ ìƒí˜¸ì‘ìš©í•˜ë©° ë³´ìƒì„ ìµœëŒ€í™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµí•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 178, 'prompt_tokens': 38, 'total_tokens': 216, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BgnWPpT09fo8kCjSxWJMaBzfvsC3a', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--aa8f6cc8-6761-4dde-be18-b238d3ca2586-0' usage_metadata={'input_tokens': 38, 'output_tokens': 178, 'total_tokens': 216, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    response = llm.invoke(prompt)\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e81b234",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate\n",
    "- SystemMessagePromptTemplate, HumanMessagePromptTemplate, \n",
    "AIMessagePromptTemplate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca0ccaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep learning is a subfield of machine learning that involves building and training artificial neural networks with multiple layers (hence the term \"deep\"). These neural networks are designed to automatically learn and represent complex patterns and relationships within data. Deep learning has seen significant advancements in recent years, particularly with the use of deep neural networks known as convolutional neural networks (CNNs) for image recognition, recurrent neural networks (RNNs) for sequential data processing, and transformers for natural language processing tasks. Deep learning has been applied successfully in various domains such as computer vision, speech recognition, natural language processing, and reinforcement learning. Its ability to automatically learn hierarchical representations from data has led to improved performance in tasks that were previously considered challenging for traditional machine learning algorithms.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ê°œë³„ ë©”ì‹œì§€ í…œí”Œë¦¿ ì •ì˜\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an {topic} expert. Please provide clear and detailed explanations.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplateë¡œ ë©”ì‹œì§€ë“¤ì„ ë¬¶ê¸°\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# ë©”ì‹œì§€ ìƒì„±\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"What is deep learning?\")\n",
    "\n",
    "# LLM í˜¸ì¶œ\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aa9231",
   "metadata": {},
   "source": [
    "### FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cda78d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### íƒœì–‘ê³„ì˜ í–‰ì„±ë“¤\n",
      "\n",
      "1. **ìˆ˜ì„±**: íƒœì–‘ì— ê°€ì¥ ê°€ê¹Œìš´ í–‰ì„±ìœ¼ë¡œ, ë§¤ìš° ëœ¨ê²ê³  ë‚®ì—ëŠ” ì˜¨ë„ê°€ ë†’ê³  ë°¤ì—ëŠ” ë§¤ìš° ì°¨ê°€ì›Œìš”.\n",
      "\n",
      "2. **ê¸ˆì„±**: ì§€êµ¬ì™€ ë¹„ìŠ·í•œ í¬ê¸°ì§€ë§Œ, ë‘êº¼ìš´ êµ¬ë¦„ìœ¼ë¡œ ë®ì—¬ ìˆì–´ ë§¤ìš° ëœ¨ê²ê³ , ì˜¨ì‹¤ íš¨ê³¼ê°€ ê°•í•´ìš”.\n",
      "\n",
      "3. **ì§€êµ¬**: ìƒëª…ì²´ê°€ ì‚´ ìˆ˜ ìˆëŠ” ìœ ì¼í•œ í–‰ì„±ìœ¼ë¡œ, ë¬¼ì´ ì•¡ì²´ ìƒíƒœë¡œ ì¡´ì¬í•´ìš”.\n",
      "\n",
      "4. **í™”ì„±**: ë¶‰ì€ìƒ‰ì„ ë ê³  ìˆìœ¼ë©°, ë¬¼ì´ ìˆì—ˆë˜ í”ì ì´ ìˆì–´ìš”. íƒì‚¬ ë¡œë´‡ë“¤ì´ ë§ì´ ê°€ê³  ìˆì–´ìš”.\n",
      "\n",
      "5. **ëª©ì„±**: íƒœì–‘ê³„ì—ì„œ ê°€ì¥ í° í–‰ì„±ìœ¼ë¡œ, ë§ì€ ìœ„ì„±ì„ ê°€ì§€ê³  ìˆê³ , ëŒ€ì ë°˜ì´ë¼ëŠ” í° í­í’ì´ ìˆì–´ìš”.\n",
      "\n",
      "6. **í† ì„±**: ì•„ë¦„ë‹¤ìš´ ê³ ë¦¬ë¡œ ìœ ëª…í•œ í–‰ì„±ìœ¼ë¡œ, ê°€ìŠ¤ í–‰ì„±ì´ì—ìš”.\n",
      "\n",
      "7. **ì²œì™•ì„±**: ì˜†ìœ¼ë¡œ ëˆ„ì›Œì„œ ëŒê³  ìˆëŠ” ë…íŠ¹í•œ í–‰ì„±ìœ¼ë¡œ, í‘¸ë¥¸ìƒ‰ì„ ë ê³  ìˆì–´ìš”.\n",
      "\n",
      "8. **í•´ì™•ì„±**: íƒœì–‘ê³„ì—ì„œ ê°€ì¥ ë¨¼ í–‰ì„±ìœ¼ë¡œ, ê°•í•œ ë°”ëŒê³¼ í­í’ì´ íŠ¹ì§•ì´ì—ìš”. \n",
      "\n",
      "ì´ë ‡ê²Œ íƒœì–‘ê³„ì—ëŠ” ì´ 8ê°œì˜ í–‰ì„±ì´ ìˆì–´ìš”!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.\",\n",
    "        \"output\": \"\"\"### ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™\n",
    "        1. **ê´€ì„±ì˜ ë²•ì¹™**: í˜ì´ ì‘ìš©í•˜ì§€ ì•Šìœ¼ë©´ ë¬¼ì²´ëŠ” ê³„ì† ê°™ì€ ìƒíƒœë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\n",
    "        2. **ê°€ì†ë„ì˜ ë²•ì¹™**: ë¬¼ì²´ì— í˜ì´ ì‘ìš©í•˜ë©´, í˜ê³¼ ì§ˆëŸ‰ì— ë”°ë¼ ê°€ì†ë„ê°€ ê²°ì •ë©ë‹ˆë‹¤.\n",
    "        3. **ì‘ìš©-ë°˜ì‘ìš© ë²•ì¹™**: ëª¨ë“  í˜ì—ëŠ” í¬ê¸°ê°€ ê°™ê³  ë°©í–¥ì´ ë°˜ëŒ€ì¸ í˜ì´ ì‘ìš©í•©ë‹ˆë‹¤.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"ì§€êµ¬ì˜ ëŒ€ê¸° êµ¬ì„± ìš”ì†Œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\",\n",
    "        \"output\": \"\"\"### ì§€êµ¬ ëŒ€ê¸°ì˜ êµ¬ì„±\n",
    "        - **ì§ˆì†Œ (78%)**: ëŒ€ê¸°ì˜ ëŒ€ë¶€ë¶„ì„ ì°¨ì§€í•©ë‹ˆë‹¤.\n",
    "        - **ì‚°ì†Œ (21%)**: ìƒëª…ì²´ê°€ í˜¸í¡í•˜ëŠ” ë° í•„ìš”í•©ë‹ˆë‹¤.\n",
    "        - **ì•„ë¥´ê³¤ (0.93%)**: ë°˜ì‘ì„±ì´ ë‚®ì€ ê¸°ì²´ì…ë‹ˆë‹¤.\n",
    "        - **ì´ì‚°í™”íƒ„ì†Œ (0.04%)**: ê´‘í•©ì„± ë° ì˜¨ì‹¤ íš¨ê³¼ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# ì˜ˆì œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate ì ìš©\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ê³¼í•™ êµìœ¡ìì…ë‹ˆë‹¤.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ìƒì„± ë° ì²´ì¸ êµ¬ì„±\n",
    "model = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "chain = final_prompt | model\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "result = chain.invoke({\"input\": \"íƒœì–‘ê³„ì˜ í–‰ì„±ë“¤ì„ ê°„ëµíˆ ì •ë¦¬í•´ ì£¼ì„¸ìš”.\"})\n",
    "#result = chain.invoke({\"input\": \"ì–‘ì ì–½í˜ì´ ë¬´ì—‡ì¸ê°€ìš”?\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26fd471",
   "metadata": {},
   "source": [
    "### PartialPromptTemplate\n",
    "* í”„ë¡¬í”„íŠ¸ì˜ ì…ë ¥ê°’ì„ ë™ì ìœ¼ë¡œ í™œìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83c8bf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ í”„ë¡¬í”„íŠ¸: input_variables=['season'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['season'], input_types={}, partial_variables={}, template='{season}ì— ì£¼ë¡œ ë°œìƒí•˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒ 3ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. ê° í˜„ìƒì— ëŒ€í•´ ê°„ë‹¨í•œ ì„¤ëª…ì„ í¬í•¨í•´ì£¼ì„¸ìš”.'), additional_kwargs={})]\n",
      "ğŸ”¹ ëª¨ë¸ ì‘ë‹µ: ê²¨ìš¸ì— ë°œìƒí•˜ëŠ” ìì—° í˜„ìƒ : \n",
      " 1.  **ê·¹ê´‘**: ê·¹ì§€ë°©ì—ì„œ ë°œìƒí•˜ëŠ” í˜„ìƒìœ¼ë¡œ íƒœì–‘í’ì´ ì§€êµ¬ ìê¸°ì¥ì— ì˜í•´ ê·¹ì§€ë°©ìœ¼ë¡œ ìœ ì…ë˜ì–´ ëŒ€ê¸° ì¤‘ì˜ ì›ìì™€ ë¶„ìì™€ ì¶©ëŒí•˜ë©´ì„œ ë°œìƒí•˜ëŠ” ë¹›ì…ë‹ˆë‹¤. íƒœì–‘í’ì˜ ê°•ë„ê°€ ê°•í•´ì§€ë©´ ê·¹ê´‘ì´ ë” ë°ê³  ìì£¼ ë°œìƒí•˜ë©°, ê·¹ê´‘ì€ ë¶ê·¹ì—ì„œëŠ” ì˜¤ë¡œë¼ ë³´ë ˆì•Œë¦¬ìŠ¤(Aurora Borealis), ë‚¨ê·¹ì—ì„œëŠ” ì˜¤ë¡œë¼ ì˜¤ìŠ¤íŠ¸ë„ë¦¬ìŠ¤(Aurora Australis)ë¡œ ë¶ˆë¦½ë‹ˆë‹¤.\n",
      "2.  **ì„±ì¸µê¶Œì˜ ì˜¨ë„ê°€ ë‚®ì•„ì§**: ì„±ì¸µê¶Œì€ ëŒ€ê¸°ì˜ ì¤‘ê°„ì¸µìœ¼ë¡œ, ì¼ë°˜ì ìœ¼ë¡œ ê³ ë„ê°€ ë†’ì„ìˆ˜ë¡ ì˜¨ë„ê°€ ë‚®ì•„ì§€ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ê²¨ìš¸ì—ëŠ” ì„±ì¸µê¶Œì˜ ì˜¨ë„ê°€ ë” ë‚®ì•„ì§€ëŠ” í˜„ìƒì´ ë°œìƒí•©ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ìƒì¸µ ëŒ€ê¸°ê°€ ê·¹ë„ë¡œ ì°¨ê°€ì›Œì§€ê³ , ì´ëŠ” ëŒ€ê¸° ìˆœí™˜ê³¼ ê¸°ìƒ í˜„ìƒì— ì˜í–¥ì„ ì¤ë‹ˆë‹¤.\n",
      "3.  **ë¹™ìƒ í˜•ì„±**: ê²¨ìš¸ì—ëŠ” ê¸°ì˜¨ì´ ë‚®ì•„ì§€ë©´ì„œ ì§€í‘œë©´ì˜ ë¬¼ì´ ì–¼ì–´ ë¹™ìƒì´ í˜•ì„±ë˜ëŠ” í˜„ìƒì´ ë°œìƒí•©ë‹ˆë‹¤. íŠ¹íˆ, ìŠµí•œ í† ì–‘ì´ë‚˜ í˜¸ìˆ˜, ê°• ë“±ì—ì„œ ë¬¼ì´ ì–¼ì–´ì„œ ë¹™ìƒì´ í˜•ì„±ë˜ë©°, ì´ë¡œ ì¸í•´ ìƒíƒœê³„ì™€ ì¸ê°„ í™œë™ì— ì˜í–¥ì„ ì¤ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# ê³„ì ˆì„ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ (ë‚¨ë°˜êµ¬/ë¶ë°˜êµ¬ ê³ ë ¤)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "    \n",
    "    if hemisphere == \"north\":  # ë¶ë°˜êµ¬ (ê¸°ë³¸ê°’)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ë´„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ì—¬ë¦„\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ê°€ì„\"\n",
    "        else:\n",
    "            return \"ê²¨ìš¸\"\n",
    "    else:  # ë‚¨ë°˜êµ¬ (ê³„ì ˆ ë°˜ëŒ€)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ê°€ì„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ê²¨ìš¸\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ë´„\"\n",
    "        else:\n",
    "            return \"ì—¬ë¦„\"\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ (ë¶€ë¶„ ë³€ìˆ˜ ì ìš©)\n",
    "# prompt = PromptTemplate(\n",
    "#     template=\"{season}ì— ì¼ì–´ë‚˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒì€ {phenomenon}ì…ë‹ˆë‹¤.\",\n",
    "#     input_variables=[\"phenomenon\"],  # ì‚¬ìš©ì ì…ë ¥ í•„ìš”\n",
    "#     partial_variables={\"season\": get_current_season()}  # ë™ì ìœ¼ë¡œ ê³„ì ˆ ê°’ í• ë‹¹\n",
    "# )\n",
    "\n",
    "\n",
    "season = get_current_season(\"south\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"{season}ì— ì£¼ë¡œ ë°œìƒí•˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒ 3ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. \"\n",
    "    \"ê° í˜„ìƒì— ëŒ€í•´ ê°„ë‹¨í•œ ì„¤ëª…ì„ í¬í•¨í•´ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# íŠ¹ì • ê³„ì ˆì˜ í˜„ìƒ ì§ˆì˜\n",
    "chain = (\n",
    "    {\"season\": lambda x: season}\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "result = chain.invoke({})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ğŸ”¹ í”„ë¡¬í”„íŠ¸: {prompt}\")\n",
    "print(f\"ğŸ”¹ ëª¨ë¸ ì‘ë‹µ: {season}ì— ë°œìƒí•˜ëŠ” ìì—° í˜„ìƒ : \\n {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9857408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ í”„ë¡¬í”„íŠ¸: í˜„ì¬ 1ë‹¬ëŸ¬ = 1365.14ì› ê¸°ì¤€ìœ¼ë¡œ í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. í˜„ì¬ í™˜ìœ¨ì„ ê¸°ì¤€ìœ¼ë¡œ í•œêµ­ ê²½ì œì— ë¯¸ì¹œ ì˜í–¥ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”.\n",
      "ğŸ”¹ ëª¨ë¸ ì‘ë‹µ: ### í•œêµ­ ê²½ì œì— ë¯¸ì¹œ ì˜í–¥\n",
      "\n",
      "1. **ìˆ˜ì¶œ ì¦ê°€**: ë†’ì€ í™˜ìœ¨ì€ í•œêµ­ì˜ ìˆ˜ì¶œ ì‚°ì—…ì— ê¸ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. í•œêµ­ ì œí’ˆì´ í•´ì™¸ ì‹œì¥ì—ì„œ ë” ì €ë ´í•´ì§€ê¸° ë•Œë¬¸ì—, ìˆ˜ì¶œëŸ‰ì´ ì¦ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ìë™ì°¨, ë°˜ë„ì²´, ì² ê°• ë“± ì£¼ìš” ìˆ˜ì¶œ í’ˆëª©ì˜ ê²½ìŸë ¥ì„ ë†’ì—¬ì¤ë‹ˆë‹¤.\n",
      "\n",
      "2. **ìˆ˜ì… ë¹„ìš© ì¦ê°€**: ë°˜ë©´ì—, ë†’ì€ í™˜ìœ¨ì€ ìˆ˜ì… ë¹„ìš©ì„ ì¦ê°€ì‹œí‚µë‹ˆë‹¤. ì›ìœ , ì›ìì¬, ì‹í’ˆ ë“± ìˆ˜ì…ì— ì˜ì¡´í•˜ëŠ” ì‚°ì—…ì˜ ë¹„ìš©ì´ ì¦ê°€í•˜ì—¬, êµ­ë‚´ ë¬¼ê°€ ìƒìŠ¹ìœ¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” íŠ¹íˆ ì—ë„ˆì§€ì™€ ì‹í’ˆ ê°€ê²©ì— ë¯¼ê°í•œ ê°€ê³„ì™€ ê¸°ì—…ì— ë¶€ë‹´ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **ë¬¼ê°€ ìƒìŠ¹**: ìˆ˜ì… ë¬¼ê°€ê°€ ìƒìŠ¹í•˜ë©´, ìµœì¢… ì†Œë¹„ì¬ ê°€ê²©ë„ ìƒìŠ¹í•  ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ê°€ê³„ì˜ êµ¬ë§¤ë ¥ì„ ê°ì†Œì‹œí‚¤ê³ , ì „ë°˜ì ì¸ ê²½ì œ ì„±ì¥ì— ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. **ê´€ê´‘ê° ìœ ì¹˜**: ë†’ì€ í™˜ìœ¨ì€ í•œêµ­ì„ ë°©ë¬¸í•˜ëŠ” ì™¸êµ­ì¸ ê´€ê´‘ê°ì—ê²Œ ìœ ë¦¬í•©ë‹ˆë‹¤. ê´€ê´‘ê°ë“¤ì€ ë” ë§ì€ ì›í™”ë¥¼ ì–»ì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, í•œêµ­ì—ì„œì˜ ì†Œë¹„ê°€ ì¦ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ê´€ê´‘ ì‚°ì—…ì— ê¸ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.\n",
      "\n",
      "5. **ì™¸í™˜ì‹œì¥ ë³€ë™ì„±**: ë†’ì€ í™˜ìœ¨ì€ ì™¸í™˜ì‹œì¥ì˜ ë³€ë™ì„±ì„ ì¦ê°€ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” í™˜ìœ¨ì˜ ê¸‰ê²©í•œ ë³€ë™ìœ¼ë¡œ ì¸í•´ ê¸°ì—…ê³¼ íˆ¬ììì—ê²Œ ë¶ˆí™•ì‹¤ì„±ì„ ì¦ê°€ì‹œí‚¤ê³ , ë¦¬ìŠ¤í¬ ê´€ë¦¬ì— ì–´ë ¤ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "6. **ê¸°ì—…ì˜ ìˆ˜ìµì„±**: ìˆ˜ì¶œ ì¤‘ì‹¬ì˜ ê¸°ì—…ë“¤ì€ ë†’ì€ í™˜ìœ¨ë¡œ ì¸í•´ ìˆ˜ìµì„±ì´ ê°œì„ ë  ìˆ˜ ìˆì§€ë§Œ, ìˆ˜ì… ì˜ì¡´ë„ê°€ ë†’ì€ ê¸°ì—…ë“¤ì€ ë¹„ìš© ì¦ê°€ë¡œ ì¸í•´ ìˆ˜ìµì„±ì´ ê°ì†Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### ì¢…í•© ë¶„ì„\n",
      "\n",
      "í˜„ì¬ì˜ ë†’ì€ í™˜ìœ¨ì€ í•œêµ­ì˜ ìˆ˜ì¶œ ì‚°ì—…ì— ê¸ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆì§€ë§Œ, ìˆ˜ì… ë¹„ìš© ì¦ê°€ì™€ ë¬¼ê°€ ìƒìŠ¹ì´ë¼ëŠ” ë¶€ì •ì ì¸ ì˜í–¥ë„ ë™ë°˜í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ë¶€ëŠ” í™˜ìœ¨ì˜ ì•ˆì •ì„±ì„ ìœ ì§€í•˜ê³ , ê²½ì œ ì „ë°˜ì˜ ê· í˜•ì„ ë§ì¶”ê¸° ìœ„í•´ ì ì ˆí•œ í†µí™” ì •ì±…ì„ í¼ì³ì•¼ í•  ê²ƒì…ë‹ˆë‹¤. ë˜í•œ, ê¸°ì—…ë“¤ì€ í™˜ìœ¨ ë³€ë™ì— ë”°ë¥¸ ë¦¬ìŠ¤í¬ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•˜ì—¬, ì•ˆì •ì ì¸ ê²½ì˜ì„ ìœ ì§€í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ì‹¤ì‹œê°„ í™˜ìœ¨ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1ë‹¬ëŸ¬ = {data['rates']['KRW']}ì›\"\n",
    "\n",
    "# {info} ë³€ìˆ˜ì— APIì—ì„œ ë°›ì€ í™˜ìœ¨ ì •ë³´ë¥¼ ë™ì ìœ¼ë¡œ ë°˜ì˜\n",
    "prompt = PromptTemplate(\n",
    "    template=\"í˜„ì¬ {info} ê¸°ì¤€ìœ¼ë¡œ í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. í˜„ì¬ í™˜ìœ¨ì„ ê¸°ì¤€ìœ¼ë¡œ í•œêµ­ ê²½ì œì— ë¯¸ì¹œ ì˜í–¥ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”.\",\n",
    "    input_variables=[],  # ì‚¬ìš©ì ì…ë ¥ ì—†ìŒ\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # APIì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„° ìë™ ë°˜ì˜\n",
    ")\n",
    "\n",
    "# LLM ëª¨ë¸ ì„¤ì • (GPT-4o-mini ì‚¬ìš©)\n",
    "model = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ì— í”„ë¡¬í”„íŠ¸ ì „ë‹¬ ë° ì‘ë‹µ ë°›ê¸°\n",
    "response = model.invoke(prompt.format())\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ğŸ”¹ í”„ë¡¬í”„íŠ¸:\", prompt.format())\n",
    "print(\"ğŸ”¹ ëª¨ë¸ ì‘ë‹µ:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-farQSE-J-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
