{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eca6ee6",
   "metadata": {},
   "source": [
    "# GPT 연동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56851e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70eea580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"user\", \"{input}\")]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"LangChain은 무엇인가요? 자세하게 설명해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e078d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001F8B34F01D0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001F8B398B380> root_client=<openai.OpenAI object at 0x000001F8B32BF680> root_async_client=<openai.AsyncOpenAI object at 0x000001F8B34F0290> model_name='gpt-3.5-turbo-0125' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "# GPT API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e18cbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='LangChain은 프로그래밍 언어와 관련된 정보를 모아놓은 온라인 플랫폼입니다. 주요 기능으로는 다양한 프로그래밍 언어의 문법, 라이브러리, 프레임워크 등을 학습할 수 있는 강좌와 튜토리얼이 제공되며, 사용자들끼리 정보를 공유하고 소통할 수 있는 커뮤니티도 운영하고 있습니다. 또한 최신 프로그래밍 언어 및 기술 동향에 대한 뉴스나 이슈도 제공하여 개발자들이 항상 최신 정보를 습득할 수 있도록 도와줍니다. LangChain은 개발자들에게 유용한 정보를 종합적으로 제공하여 학습과 업무에 도움을 주는 플랫폼으로 평가받고 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 274, 'prompt_tokens': 41, 'total_tokens': 315, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BglUCx4Vz4M9nAUpwKZ3YOG3lPWMh', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--570b6703-7c4f-445e-8390-4751ce110bba-0' usage_metadata={'input_tokens': 41, 'output_tokens': 274, 'total_tokens': 315, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "응답: LangChain은 프로그래밍 언어와 관련된 정보를 모아놓은 온라인 플랫폼입니다. 주요 기능으로는 다양한 프로그래밍 언어의 문법, 라이브러리, 프레임워크 등을 학습할 수 있는 강좌와 튜토리얼이 제공되며, 사용자들끼리 정보를 공유하고 소통할 수 있는 커뮤니티도 운영하고 있습니다. 또한 최신 프로그래밍 언어 및 기술 동향에 대한 뉴스나 이슈도 제공하여 개발자들이 항상 최신 정보를 습득할 수 있도록 도와줍니다. LangChain은 개발자들에게 유용한 정보를 종합적으로 제공하여 학습과 업무에 도움을 주는 플랫폼으로 평가받고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(response)\n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-farQSE-J-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
