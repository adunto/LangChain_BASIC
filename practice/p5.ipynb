{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8202fde",
   "metadata": {},
   "source": [
    "### 문제 5-1 : 카페 메뉴 도구(Tool) 호출 체인 구현\n",
    "> 이 문제는 LangChain의 Tool Calling 기능을 학습하기 위한 기초 단계입니다. 카페 메뉴 정보를 제공하는 AI 어시스턴트를 구현하면서 다양한 데이터 소스(로컬 DB, 웹, 위키피디아)에서 정보를 검색하는 방법을 익힙니다.\n",
    "\n",
    "준비사항:\n",
    "- cafe_menu.txt 파일을 ./data/ 폴더에 저장\n",
    "- 필요한 라이브러리 설치: pip install langchain langchain-openai langchain-community langchain-ollama faiss-cpu\n",
    "- Ollama 설치 및 bge-m3 모델 다운로드\n",
    "- ollama pull bge-m3\n",
    "- 환경변수 설정 (OpenAI API 키, Tavily API 키)\n",
    "- 코드 실행하여 벡터 DB 생성 및 테스트\n",
    "\n",
    "세부사항:\n",
    "- Tool 정의 방법 이해: @tool 데코레이터를 사용한 사용자 정의 도구 생성\n",
    "- 벡터 DB 구축: 텍스트 데이터를 임베딩하여 검색 가능한 형태로 저장\n",
    "- 다중 도구 활용: 서로 다른 용도의 도구들을 하나의 LLM에 연결\n",
    "- 기본 체인 구성: 도구 호출 결과를 처리하는 간단한 워크플로우 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d52cb425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "264c2385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_core.documents import Document\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f052cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Google Gemini\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c78ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메뉴판 텍스트 데이터를 로드\n",
    "loader = TextLoader(\"../data/cafe_menu_data.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "067bad4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 10개의 메뉴 항목이 처리되었습니다.\n",
      "\n",
      "메뉴 번호: 1\n",
      "메뉴 이름: 아메리카노\n",
      "내용:\n",
      "1. 아메리카노\n",
      "   • 가격: ₩4,500\n",
      "   • 주요 원료: 에스프레소, 뜨거운 물\n",
      "   • 설명: 진한 에스프레소에 뜨거운 물을 더해 만든 클래식한 블랙 커피입니다. 원두 ...\n",
      "\n",
      "메뉴 번호: 2\n",
      "메뉴 이름: 카페라떼\n",
      "내용:\n",
      "2. 카페라떼\n",
      "   • 가격: ₩5,500\n",
      "   • 주요 원료: 에스프레소, 스팀 밀크\n",
      "   • 설명: 진한 에스프레소에 부드럽게 스팀한 우유를 넣어 만든 대표적인 밀크 커피입니다...\n"
     ]
    }
   ],
   "source": [
    "# Text Split (문서 분할)\n",
    "def split_cafe_menu(document):\n",
    "    pattern = r'(\\d+\\.\\s.*?)(?=\\n\\n\\d+\\.|$)'\n",
    "    menu_items = re.findall(pattern, document.page_content, re.DOTALL)\n",
    "    \n",
    "    # 각 메뉴 항목을 Document 객체로 변환\n",
    "    menu_documents = []\n",
    "    for i, item in enumerate(menu_items, 1):\n",
    "        # 메뉴 이름 추출\n",
    "        menu_name = item.split('\\n')[0].split('.', 1)[1].strip()\n",
    "        \n",
    "        # 새로운 Document 객체 생성\n",
    "        menu_doc = Document(\n",
    "            page_content=item.strip(),\n",
    "            metadata={\n",
    "                \"source\": document.metadata['source'],\n",
    "                \"menu_number\": i,\n",
    "                \"menu_name\": menu_name\n",
    "            }\n",
    "        )\n",
    "        menu_documents.append(menu_doc)\n",
    "    \n",
    "    return menu_documents\n",
    "\n",
    "menu_documents=[]\n",
    "for doc in documents:\n",
    "    menu_documents += split_cafe_menu(doc)\n",
    "    \n",
    "# 결과 출력\n",
    "print(f\"총 {len(menu_documents)}개의 메뉴 항목이 처리되었습니다.\")\n",
    "for doc in menu_documents[:2]:\n",
    "    print(f\"\\n메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print(f\"내용:\\n{doc.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adbd64a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# Embedding - FAISS를 사용한 벡터 인덱스 생성\n",
    "embeddings_model = OllamaEmbeddings(model=\"bge-m3:latest\") \n",
    "\n",
    "# FAISS 인덱스 생성\n",
    "menu_db = FAISS.from_documents(\n",
    "    documents=menu_documents, \n",
    "    embedding=embeddings_model\n",
    ")\n",
    "\n",
    "# FAISS 인덱스 저장\n",
    "menu_db.save_local(\"./db/cafe_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3059a471",
   "metadata": {},
   "source": [
    "### 3개의 도구를 정의하고 LLM에 바인딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c386994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tavily_search_func\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# 입력: 검색 쿼리 (str)\n",
    "# 출력: 웹 검색 결과 (str)\n",
    "\n",
    "@tool\n",
    "def tavily_search_func(query: str) -> str: \n",
    "    \"\"\"Searches the internet for information that does not exist in the database or for the latest information.\"\"\"\n",
    "    \n",
    "    tavily_search = TavilySearchResults(max_results=2)\n",
    "    docs = tavily_search.invoke(query)\n",
    "    \n",
    "    formatted_docs = \"\\n---\\n\".join([\n",
    "        f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "        for doc in docs\n",
    "        ])\n",
    "    if len(formatted_docs) > 0:\n",
    "        return formatted_docs\n",
    "    \n",
    "    return \"관련 정보를 찾을 수 없습니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27df414c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sogno\\AppData\\Local\\Temp\\ipykernel_20848\\539443416.py:37: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  wiki_summary = summary_chain.as_tool(\n"
     ]
    }
   ],
   "source": [
    "# wiki_summary\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from textwrap import dedent\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# WikipediaLoader를 사용하여 위키피디아 문서를 검색하고 텍스트로 반환하는 함수 \n",
    "def wiki_search_and_summarize(input_data: dict):\n",
    "    wiki_loader = WikipediaLoader(query=input_data[\"query\"], load_max_docs=2, lang=\"ko\")\n",
    "    wiki_docs = wiki_loader.load()\n",
    "\n",
    "    formatted_docs =[\n",
    "        f'<Document source=\"{doc.metadata[\"source\"]}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "        for doc in wiki_docs\n",
    "        ]\n",
    "    \n",
    "    return formatted_docs\n",
    "\n",
    "# 요약 프롬프트 템플릿\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the following text in a concise manner:\\n\\n{context}\\n\\nSummary:\"\n",
    ")\n",
    "\n",
    "summary_chain = (\n",
    "    {\"context\": RunnableLambda(wiki_search_and_summarize)}\n",
    "    | summary_prompt | llm | StrOutputParser() \n",
    ")\n",
    "\n",
    "# 도구 호출에 사용할 입력 스키마 정의 \n",
    "class WikiSummarySchema(BaseModel):\n",
    "    \"\"\"Input schema for Wikipedia search.\"\"\"\n",
    "    query: str = Field(..., description=\"The query to search for in Wikipedia\")\n",
    "\n",
    "\n",
    "wiki_summary = summary_chain.as_tool(\n",
    "    name=\"wiki_summary\",\n",
    "    description=dedent(\"\"\"\n",
    "        Use this tool when you need to search for information on Wikipedia.\n",
    "        It searches for Wikipedia articles related to the user's query and returns\n",
    "        a summarized text. This tool is useful when general knowledge\n",
    "        or background information is required.\n",
    "    \"\"\"),\n",
    "    args_schema=WikiSummarySchema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feede63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_search_cafe_func\n",
    "from langchain_core.documents import Document\n",
    "from typing import List\n",
    "\n",
    "# cafe db 벡터 저장소 로드\n",
    "cafe_db = FAISS.load_local(\n",
    "    \"./db/cafe_db\", \n",
    "    embeddings_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "@tool\n",
    "def db_search_cafe_func(query: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized cafe menu information from the encrypted database.\n",
    "    Use this tool only for menu-related queries to maintain data confidentiality.\n",
    "    \"\"\"\n",
    "    docs = cafe_db.similarity_search(query, k=2)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"관련 메뉴 정보를 찾을 수 없습니다.\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225218f0",
   "metadata": {},
   "source": [
    "### LLM 바인딩: bind_tools() 메서드로 3개 도구를 모두 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cbbb4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tavily_search_func, wiki_summary, db_search_cafe_func]\n",
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "585457fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "from pprint import pprint\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"You are a helpful AI assistant. Today's date is {today}.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# LLM 체인 생성\n",
    "llm_chain = prompt | llm_with_tools\n",
    "\n",
    "# 도구 실행 체인 정의\n",
    "@chain\n",
    "def cafe_menu_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "\n",
    "    tool_msgs = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "\n",
    "        if tool_call[\"name\"] == \"tavily_search_func\":\n",
    "            tool_message = tavily_search_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"wiki_summary\":\n",
    "            tool_message = wiki_summary.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"db_search_cafe_func\":\n",
    "            tool_message = db_search_cafe_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)           \n",
    "\n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26bf8b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아메리카노와 아이스 아메리카노 모두 4,500원입니다.\n"
     ]
    }
   ],
   "source": [
    "response = cafe_menu_chain.invoke(\"아메리카노 가격은?\")\n",
    "# 응답 출력 \n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe00e2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('아메리카노는 ₩4,500이며, 주요 원료는 에스프레소와 뜨거운 물입니다. 진한 에스프레소에 뜨거운 물을 더해 만든 클래식한 블랙 커피로, '\n",
      " '원두 본연의 맛을 가장 잘 느낄 수 있으며, 깔끔하고 깊은 풍미가 특징입니다. 아이스 아메리카노 또한 ₩4,500이며, 주요 원료는 '\n",
      " '에스프레소, 차가운 물, 얼음입니다. 깔끔하고 시원한 맛이 특징이며, 원두 본연의 풍미를 느낄 수 있습니다.')\n"
     ]
    }
   ],
   "source": [
    "response = cafe_menu_chain.invoke(\"아메리카노의 가격과 특징은 무엇인가요?\")\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4d599c",
   "metadata": {},
   "source": [
    "### 문제 5-2 : Few-shot 프롬프팅을 활용한 카페 AI 어시스턴트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed42a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f9900d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카페 메뉴(카푸치노)에 맞게 프롬프트 예시를 구성합니다.\n",
    "\n",
    "examples = [\n",
    "    HumanMessage(\"카푸치노의 가격과 특징을 알려주세요.\", name=\"example_user\"),\n",
    "    AIMessage(\"카푸치노 메뉴 정보를 데이터베이스에서 검색하겠습니다.\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"db_search_cafe_func\", \"args\": {\"query\": \"카푸치노\"}, \"id\": \"1\"}]),\n",
    "    ToolMessage(\"카푸치노: 가격 ₩5,000, 에스프레소, 스팀 밀크, 우유 거품이 1:1:1 비율로 구성된 이탈리아 전통 커피입니다. 진한 커피 맛과 부드러운 우유 거품의 조화가 일품이며, 계피 파우더를 뿌려 제공합니다.\", tool_call_id=\"1\"),\n",
    "    AIMessage(\"카푸치노의 가격은 ₩5,000이며, 에스프레소, 스팀 밀크, 우유 거품이 1:1:1 비율로 구성된 이탈리아 전통 커피입니다. 진한 커피 맛과 부드러운 우유 거품의 조화가 일품이며, 계피 파우더를 뿌려 제공합니다. 추가 정보를 위키피디아에서 찾아보겠습니다.\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"wiki_summary\", \"args\": {\"query\": \"카푸치노\"}, \"id\": \"2\"}]),\n",
    "    ToolMessage(\"카푸치노는 에스프레소에 뜨거운 우유와 우유 거품을 더한 이탈리아식 커피 음료입니다. 이름은 카푸친 수도사의 갈색 옷에서 유래되었습니다.\", tool_call_id=\"2\"),\n",
    "    AIMessage(\"카푸치노는 에스프레소에 뜨거운 우유와 우유 거품을 더한 이탈리아식 커피 음료로, 부드러운 맛과 풍부한 거품이 특징입니다.\", name=\"example_assistant\"),\n",
    "]\n",
    "\n",
    "system = \"\"\"You are an AI assistant providing cafe menu information.\n",
    "For information about the cafe's menu, use the search_cafe tool.\n",
    "For other general information, use the wiki_summary tool.\n",
    "If additional web searches are needed or for the most up-to-date information, use the search_web tool.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fffd10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "few_shot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system + f\"Today's date is {today}.\"),\n",
    "    *examples,\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cc10c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Gemini\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29fbab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 도구를 직접 LLM에 바인딩 가능\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "# Few-shot 프롬프트를 사용한 체인 구성\n",
    "fewshot_search_chain = few_shot_prompt | llm_with_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb30f442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 실행 체인 정의\n",
    "@chain\n",
    "def cafe_menu_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = fewshot_search_chain.invoke(input_, config=config)\n",
    "\n",
    "    tool_msgs = []\n",
    "    \n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "\n",
    "        # [tavily_search_func, wiki_summary, db_search_menu_func, db_search_wine_func]\n",
    "        if tool_call[\"name\"] == \"tavily_search_func\":\n",
    "            tool_message = tavily_search_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"wiki_summary\":\n",
    "            tool_message = wiki_summary.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"db_search_cafe_func\":\n",
    "            tool_message = db_search_cafe_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)         \n",
    "\n",
    "    return fewshot_search_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19496281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sogno\\AppData\\Local\\Temp\\ipykernel_20848\\2880866804.py:12: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily_search = TavilySearchResults(max_results=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('카푸치노와 어울리는 디저트는 검색 결과에서 찾을 수 없었습니다. 하지만 일반적으로 카푸치노는 달콤한 디저트와 잘 어울립니다. 예를 들어, '\n",
      " '케이크, 쿠키, 타르트 등이 좋은 선택이 될 수 있습니다. 특히 초콜릿 케이크나 치즈 케이크는 카푸치노의 풍부한 맛과 잘 어울립니다.\\n'\n",
      " '\\n'\n",
      " '라떼는 오스트리아에서 유래되어 이탈리아에서 개발되었으며, 카푸치노와 들어가는 재료는 같지만 비율의 차이가 있습니다. 라떼는 에스프레소에 '\n",
      " '우유를 더한 음료로, 카푸치노보다 우유의 비율이 높습니다.')\n"
     ]
    }
   ],
   "source": [
    "# 체인 실행\n",
    "query = \"카푸치노와 어울리는 디저트는 무엇인가요? 그리고 라떼의 유래에 대해서도 알려주세요.\"\n",
    "response = cafe_menu_chain.invoke(query)\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-farQSE-J-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
