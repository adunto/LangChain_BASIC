{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce68433a",
   "metadata": {},
   "source": [
    "# Embedding 개요\n",
    "\n",
    "## 1. 임베딩(Embedding)이란?\n",
    "\n",
    "임베딩(Embedding)은 Retrieval-Augmented Generation(RAG) 시스템의 세 번째 단계로, 문서 분할 단계에서 생성된 문서 단위를 기계가 이해할 수 있는 수치적 형태(벡터)로 변환하는 과정입니다.\n",
    "\n",
    "이 과정은 RAG 시스템의 핵심 요소 중 하나로, 문서의 의미를 벡터(숫자의 배열) 형태로 표현함으로써 사용자가 입력한 질문(Query)에 대해 DB에 저장된 문서 조각(Chunk)을 검색하고 유사도를 계산하는 데 활용됩니다.\n",
    "\n",
    "## 2. 임베딩의 주요 활용 사례\n",
    "\n",
    "### 2.1 의미 검색(Semantic Search)\n",
    "\n",
    "- 벡터 표현을 활용하여 의미적으로 유사한 텍스트를 검색하는 방식\n",
    "- 사용자가 입력한 쿼리에 대해 가장 관련성이 높은 문서나 정보를 효과적으로 찾아낼 수 있음\n",
    "\n",
    "### 2.2 문서 분류(Document Classification)\n",
    "\n",
    "- 임베딩된 텍스트 벡터를 사용하여 문서를 특정 카테고리나 주제로 분류하는 작업\n",
    "- 뉴스 분류, 고객 피드백 분석 등 다양한 자연어 처리(NLP) 응용 가능\n",
    "\n",
    "### 2.3 텍스트 유사도 계산(Text Similarity Calculation)\n",
    "\n",
    "- 두 개의 텍스트 벡터 사이의 거리를 계산하여 유사도를 평가\n",
    "- 예를 들어, 코사인 유사도(Cosine Similarity)를 활용하여 두 문장이 얼마나 비슷한지 수치화할 수 있음\n",
    "\n",
    "## 3. 임베딩 모델 제공자\n",
    "\n",
    "### 3.1 OpenAI\n",
    "\n",
    "- GPT 계열 모델을 기반으로 텍스트 임베딩을 생성할 수 있는 API 제공\n",
    "- 대표적인 임베딩 모델: `text-embedding-3-small`, `text-embedding-ada-002` 등\n",
    "\n",
    "### 3.2 Hugging Face\n",
    "\n",
    "- `Transformers` 라이브러리를 통해 다양한 오픈소스 임베딩 모델 제공\n",
    "- 대표적인 모델: `sentence-transformers` 계열 (`all-MiniLM-L6-v2` 등)\n",
    "\n",
    "### 3.3 Google\n",
    "\n",
    "- `Gemini`, `Gemma` 등의 언어 모델에 적용되는 임베딩 모델 제공\n",
    "- Google의 `Vertex AI`에서도 다양한 임베딩 모델을 지원\n",
    "\n",
    "## 4. 임베딩 메소드\n",
    "\n",
    "### 4.1 `embed_documents`\n",
    "\n",
    "- 문서 객체의 집합을 입력으로 받아 각 문서를 벡터 공간에 임베딩 하는 메소드\n",
    "- 대량의 텍스트 데이터를 배치(batch) 단위로 처리할 때 유용\n",
    "\n",
    "### 4.2 `embed_query`\n",
    "\n",
    "- 단일 텍스트 쿼리를 입력으로 받아, 이를 벡터 공간에 임베딩 하는 메소드\n",
    "- 사용자의 검색 쿼리를 벡터화하여 문서 집합 내에서 가장 관련성이 높은 내용을 찾아내는 데 활용\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
