{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07251274",
   "metadata": {},
   "source": [
    "## RecursiveCharacterTextSplitter\n",
    "`RecursiveCharacterTextSplitter`는 문서를 분할할 때 **설정된 문자 목록을 순서대로 사용하여 가장 적절한 크기로 나누는 방식**입니다.\n",
    "\n",
    "- 우선적으로 `\"\\n\\n\"`(문단 단위)로 분할을 시도하고, 이후 `\"\\n\"`(줄 단위) → `\" \"`(단어 단위) → `\"\"`(문자 단위) 순으로 진행됨.\n",
    "- `RecursiveCharacterTextSplitter`는 문단 → 문장 → 단어 순으로 분할을 시도하여 문장이 끊기지 않도록 **가능한 한 문맥을 유지한 상태로 텍스트를 나눌 수 있음**.\n",
    "- 문맥 유지를 위한 설정\n",
    "    - `chunk_overlap`은 chunk_size의 20~30% 정도로 설정함\n",
    "    - **`separators`를 활용해 의미 단위로 끊기도록 조정** (`[\"\\n\\n\", \".\", \"!\", \"?\", \" \", \"\"]`)\n",
    "- 연구 논문, 기술 문서처럼 **구조가 명확하지 않은 긴 텍스트를 효과적으로 나눌 때 유용함**\n",
    "- 계층적 분할로 **의미 단위를 최대한 보존**하면서 적절한 크기의 청크를 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36441be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chunk 1: RAG는 검색과 생성 단계를 포함하는 모델입니다.\n",
      "\n",
      " Chunk 2: 이 모델은 검색 기반의 텍스트 생성 기능을 제공합니다.\n",
      "특히, 최신 데이터를 반영하는 데 강력한 기능을 가지고 있습니다.\n",
      "\n",
      " Chunk 3: Transformer 모델을 기반으로 실시간 정보를 활용할 수 있으며, 기존의 단순한 생성 모델보다 더 정확한 답변을 제공합니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 간단 예제\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text = \"\"\"RAG는 검색과 생성 단계를 포함하는 모델입니다.\n",
    "\n",
    "이 모델은 검색 기반의 텍스트 생성 기능을 제공합니다.\n",
    "특히, 최신 데이터를 반영하는 데 강력한 기능을 가지고 있습니다.\n",
    "\n",
    "Transformer 모델을 기반으로 실시간 정보를 활용할 수 있으며, 기존의 단순한 생성 모델보다 더 정확한 답변을 제공합니다.\"\"\"\n",
    "\n",
    "# 의미 단위(문장, 단락)로 나누되, chunk_size 50 제한\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=80, chunk_overlap=20, separators=[\"\\n\\n\", \".\", \"!\", \"?\", \" \", \"\"])\n",
    "chunks = splitter.split_text(text)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\" Chunk {i+1}: {chunk}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2479f398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 텍스트:\n",
      "--------------------------------------------------\n",
      "RAG는 검색과 생성 단계를 포함하는 모델입니다.\n",
      "\n",
      "이 모델은 검색 기반의 텍스트 생성 기능을 제공합니다.\n",
      "특히, 최신 데이터를 반영하는 데 강력한 기능을 가지고 있습니다.\n",
      "\n",
      "Transformer 모델을 기반으로 실시간 정보를 활용할 수 있으며, 기존의 단순한 생성 모델보다 더 정확한 답변을 제공합니다.\n",
      "\n",
      "RAG의 핵심은 검색과 생성의 결합입니다! 먼저 관련 문서를 찾고, 그 정보를 바탕으로 답변을 만듭니다.\n",
      "\n",
      "텍스트 길이: 230자\n",
      "\n",
      "============================================================\n",
      "RecursiveCharacterTextSplitter vs CharacterTextSplitter 비교\n",
      "============================================================\n",
      "\n",
      "1. RecursiveCharacterTextSplitter (계층적 분할):\n",
      "---------------------------------------------\n",
      "Chunk 1: 'RAG는 검색과 생성 단계를 포함하는 모델입니다.'\n",
      "길이: 27자\n",
      "\n",
      "Chunk 2: '이 모델은 검색 기반의 텍스트 생성 기능을 제공합니다.\n",
      "특히, 최신 데이터를 반영하는 데 강력한 기능을 가지고 있습니다.'\n",
      "길이: 67자\n",
      "\n",
      "Chunk 3: 'Transformer 모델을 기반으로 실시간 정보를 활용할 수 있으며, 기존의 단순한 생성 모델보다 더 정확한 답변을 제공합니다.'\n",
      "길이: 72자\n",
      "\n",
      "Chunk 4: 'RAG의 핵심은 검색과 생성의 결합입니다! 먼저 관련 문서를 찾고, 그 정보를 바탕으로 답변을 만듭니다.'\n",
      "길이: 58자\n",
      "\n",
      "2. CharacterTextSplitter (단순 분할):\n",
      "-----------------------------------\n",
      "Chunk 1: 'RAG는 검색과 생성 단계를 포함하는 모델입니다.\n",
      "\n",
      "이 모델은 검색 기반의 텍스트 생성 기능을 제공합니다'\n",
      "길이: 58자\n",
      "\n",
      "Chunk 2: '특히, 최신 데이터를 반영하는 데 강력한 기능을 가지고 있습니다'\n",
      "길이: 35자\n",
      "\n",
      "Chunk 3: 'Transformer 모델을 기반으로 실시간 정보를 활용할 수 있으며, 기존의 단순한 생성 모델보다 더 정확한 답변을 제공합니다'\n",
      "길이: 71자\n",
      "\n",
      "Chunk 4: 'RAG의 핵심은 검색과 생성의 결합입니다! 먼저 관련 문서를 찾고, 그 정보를 바탕으로 답변을 만듭니다'\n",
      "길이: 57자\n",
      "\n",
      "============================================================\n",
      "separators 우선순위 동작 확인\n",
      "============================================================\n",
      "테스트 텍스트:\n",
      "'첫 번째 문단입니다.\\n\\n두 번째 문단입니다.\\n이 문단은 여러 문장으로 구성됩니다! 정말 흥미롭죠?\\n\\n세 번째 문단입니다.'\n",
      "\n",
      "문단 우선 separators=['\\n\\n', '\\n', '.', ' ']:\n",
      "  Chunk 1: '첫 번째 문단입니다.'\n",
      "  Chunk 2: '두 번째 문단입니다.'\n",
      "  Chunk 3: '이 문단은 여러 문장으로 구성됩니다! 정말 흥미롭죠?'\n",
      "  Chunk 4: '세 번째 문단입니다.'\n",
      "\n",
      "줄바꿈 우선 separators=['\\n', '.', ' ']:\n",
      "  Chunk 1: '첫 번째 문단입니다.\n",
      "\n",
      "두 번째 문단입니다.'\n",
      "  Chunk 2: '이 문단은 여러 문장으로 구성됩니다! 정말 흥미롭죠?'\n",
      "  Chunk 3: '세 번째 문단입니다.'\n",
      "\n",
      "문장 우선 separators=['.', '!', '?', ' ']:\n",
      "  Chunk 1: '첫 번째 문단입니다.\n",
      "\n",
      "두 번째 문단입니다'\n",
      "  Chunk 2: '.\n",
      "이 문단은 여러 문장으로 구성됩니다'\n",
      "  Chunk 3: '! 정말 흥미롭죠?\n",
      "\n",
      "세 번째 문단입니다'\n",
      "  Chunk 4: '.'\n",
      "\n",
      "단어 단위 separators=[' ']:\n",
      "  Chunk 1: '첫 번째 문단입니다.\n",
      "\n",
      "두 번째 문단입니다.\n",
      "이 문단은 여러 문장으로'\n",
      "  Chunk 2: '여러 문장으로 구성됩니다! 정말 흥미롭죠?\n",
      "\n",
      "세 번째 문단입니다.'\n",
      "\n",
      "============================================================\n",
      "chunk_size별 분할 결과 비교\n",
      "============================================================\n",
      "\n",
      "chunk_size=50:\n",
      "총 9개 청크 생성\n",
      "평균 청크 길이: 28.8자\n",
      "  Chunk 1: 'RAG는 검색과 생성 단계를 포함하는 모델입니다....' (길이: 27자)\n",
      "  Chunk 2: '이 모델은 검색 기반의 텍스트 생성 기능을 제공합니다....' (길이: 30자)\n",
      "  Chunk 3: '특히, 최신 데이터를 반영하는 데 강력한 기능을 가지고...' (길이: 36자)\n",
      "  Chunk 4: 'Transformer 모델을 기반으로 실시간 정보를 활...' (길이: 47자)\n",
      "  Chunk 5: '활용할 수 있으며, 기존의 단순한 생성 모델보다 더 정...' (길이: 42자)\n",
      "  Chunk 6: '....' (길이: 1자)\n",
      "  Chunk 7: 'RAG의 핵심은 검색과 생성의 결합입니다! 먼저 관련 ...' (길이: 48자)\n",
      "  Chunk 8: '문서를 찾고, 그 정보를 바탕으로 답변을 만듭니다...' (길이: 27자)\n",
      "  Chunk 9: '....' (길이: 1자)\n",
      "\n",
      "chunk_size=100:\n",
      "총 3개 청크 생성\n",
      "평균 청크 길이: 75.3자\n",
      "  Chunk 1: 'RAG는 검색과 생성 단계를 포함하는 모델입니다.\n",
      "\n",
      "이...' (길이: 96자)\n",
      "  Chunk 2: 'Transformer 모델을 기반으로 실시간 정보를 활...' (길이: 72자)\n",
      "  Chunk 3: 'RAG의 핵심은 검색과 생성의 결합입니다! 먼저 관련 ...' (길이: 58자)\n",
      "\n",
      "chunk_size=150:\n",
      "총 2개 청크 생성\n",
      "평균 청크 길이: 114.0자\n",
      "  Chunk 1: 'RAG는 검색과 생성 단계를 포함하는 모델입니다.\n",
      "\n",
      "이...' (길이: 96자)\n",
      "  Chunk 2: 'Transformer 모델을 기반으로 실시간 정보를 활...' (길이: 132자)\n",
      "\n",
      "============================================================\n",
      "chunk_overlap 효과 확인\n",
      "============================================================\n",
      "\n",
      "chunk_overlap=0:\n",
      "총 4개 청크 생성\n",
      "  Chunk 1: 'RAG는 검색과 생성 단계를 포함하는 모델입니다.'\n",
      "  Chunk 2: '이 모델은 검색 기반의 텍스트 생성 기능을 제공합니다.\n",
      "특히, 최신 데이터를 반영하는 데 강력한 기능을 가지고 있습니다.'\n",
      "  Chunk 3: 'Transformer 모델을 기반으로 실시간 정보를 활용할 수 있으며, 기존의 단순한 생성 모델보다 더 정확한 답변을 제공합니다.'\n",
      "  Chunk 4: 'RAG의 핵심은 검색과 생성의 결합입니다! 먼저 관련 문서를 찾고, 그 정보를 바탕으로 답변을 만듭니다.'\n",
      "\n",
      "chunk_overlap=10:\n",
      "총 4개 청크 생성\n",
      "  Chunk 1: 'RAG는 검색과 생성 단계를 포함하는 모델입니다.'\n",
      "  Chunk 2: '이 모델은 검색 기반의 텍스트 생성 기능을 제공합니다.\n",
      "특히, 최신 데이터를 반영하는 데 강력한 기능을 가지고 있습니다.'\n",
      "  Chunk 3: 'Transformer 모델을 기반으로 실시간 정보를 활용할 수 있으며, 기존의 단순한 생성 모델보다 더 정확한 답변을 제공합니다.'\n",
      "  Chunk 4: 'RAG의 핵심은 검색과 생성의 결합입니다! 먼저 관련 문서를 찾고, 그 정보를 바탕으로 답변을 만듭니다.'\n",
      "\n",
      "chunk_overlap=30:\n",
      "총 4개 청크 생성\n",
      "  Chunk 1: 'RAG는 검색과 생성 단계를 포함하는 모델입니다.'\n",
      "  Chunk 2: '이 모델은 검색 기반의 텍스트 생성 기능을 제공합니다.\n",
      "특히, 최신 데이터를 반영하는 데 강력한 기능을 가지고 있습니다.'\n",
      "  Chunk 3: 'Transformer 모델을 기반으로 실시간 정보를 활용할 수 있으며, 기존의 단순한 생성 모델보다 더 정확한 답변을 제공합니다.'\n",
      "  Chunk 4: 'RAG의 핵심은 검색과 생성의 결합입니다! 먼저 관련 문서를 찾고, 그 정보를 바탕으로 답변을 만듭니다.'\n",
      "\n",
      "============================================================\n",
      "실무 활용 가이드\n",
      "============================================================\n",
      "\n",
      "RecursiveCharacterTextSplitter 사용 가이드:\n",
      "\n",
      "1. 기본 설정 (일반적 문서):\n",
      "   chunk_size=1000, chunk_overlap=200\n",
      "   separators=[\"\n",
      "\n",
      "\", \"\n",
      "\", \".\", \" \"]\n",
      "\n",
      "2. 한국어 문서 최적화:\n",
      "   chunk_size=500-1000, chunk_overlap=100-200\n",
      "   separators=[\"\n",
      "\n",
      "\", \"\n",
      "\", \".\", \"。\", \" \"]\n",
      "\n",
      "3. 코드 문서:\n",
      "   separators=[\"\n",
      "\n",
      "\", \"\n",
      "\", \"\t\", \" \"]\n",
      "\n",
      "4. 대화/채팅 로그:\n",
      "   separators=[\"\n",
      "\n",
      "\", \"\n",
      "\", \":\", \" \"]\n",
      "\n",
      "장점:\n",
      "- 의미 단위로 자연스러운 분할\n",
      "- 계층적 구분자로 최적화된 분할점 찾기\n",
      "- 텍스트 특성에 맞는 유연한 설정\n",
      "\n",
      "주의사항:\n",
      "- chunk_size는 LLM 토큰 제한 고려\n",
      "- chunk_overlap은 맥락 보존과 비용의 균형\n",
      "- separators 순서가 분할 품질 결정\n",
      "\n",
      "\n",
      "프로그램 완료\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 예제 텍스트\n",
    "text = \"\"\"RAG는 검색과 생성 단계를 포함하는 모델입니다.\n",
    "\n",
    "이 모델은 검색 기반의 텍스트 생성 기능을 제공합니다.\n",
    "특히, 최신 데이터를 반영하는 데 강력한 기능을 가지고 있습니다.\n",
    "\n",
    "Transformer 모델을 기반으로 실시간 정보를 활용할 수 있으며, 기존의 단순한 생성 모델보다 더 정확한 답변을 제공합니다.\n",
    "\n",
    "RAG의 핵심은 검색과 생성의 결합입니다! 먼저 관련 문서를 찾고, 그 정보를 바탕으로 답변을 만듭니다.\"\"\"\n",
    "\n",
    "print(\"원본 텍스트:\")\n",
    "print(\"-\" * 50)\n",
    "print(text)\n",
    "print(f\"\\n텍스트 길이: {len(text)}자\")\n",
    "\n",
    "# ===========================================\n",
    "# Recursive vs Character 비교\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RecursiveCharacterTextSplitter vs CharacterTextSplitter 비교\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. RecursiveCharacterTextSplitter (추천)\n",
    "print(\"\\n1. RecursiveCharacterTextSplitter (계층적 분할):\")\n",
    "print(\"-\" * 45)\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=80,\n",
    "    chunk_overlap=20,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \" \", \"\"]  # 우선순위 순서\n",
    ")\n",
    "recursive_chunks = recursive_splitter.split_text(text)\n",
    "\n",
    "for i, chunk in enumerate(recursive_chunks):\n",
    "    print(f\"Chunk {i+1}: '{chunk.strip()}'\")\n",
    "    print(f\"길이: {len(chunk)}자\")\n",
    "    print()\n",
    "\n",
    "# 2. CharacterTextSplitter (비교용)\n",
    "print(\"2. CharacterTextSplitter (단순 분할):\")\n",
    "print(\"-\" * 35)\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "simple_splitter = CharacterTextSplitter(\n",
    "    chunk_size=80,\n",
    "    chunk_overlap=20,\n",
    "    separator=\".\"  # 하나의 구분자만 사용\n",
    ")\n",
    "simple_chunks = simple_splitter.split_text(text)\n",
    "\n",
    "for i, chunk in enumerate(simple_chunks):\n",
    "    print(f\"Chunk {i+1}: '{chunk.strip()}'\")\n",
    "    print(f\"길이: {len(chunk)}자\")\n",
    "    print()\n",
    "\n",
    "# ===========================================\n",
    "# separators 우선순위 테스트\n",
    "# ===========================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"separators 우선순위 동작 확인\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_text = \"\"\"첫 번째 문단입니다.\n",
    "\n",
    "두 번째 문단입니다.\n",
    "이 문단은 여러 문장으로 구성됩니다! 정말 흥미롭죠?\n",
    "\n",
    "세 번째 문단입니다.\"\"\"\n",
    "\n",
    "print(\"테스트 텍스트:\")\n",
    "print(repr(test_text))  # 줄바꿈 문자까지 보이도록\n",
    "\n",
    "# 다양한 separators 설정 테스트\n",
    "separators_configs = [\n",
    "    ([\"\\n\\n\", \"\\n\", \".\", \" \"], \"문단 우선\"),\n",
    "    ([\"\\n\", \".\", \" \"], \"줄바꿈 우선\"),\n",
    "    ([\".\", \"!\", \"?\", \" \"], \"문장 우선\"),\n",
    "    ([\" \"], \"단어 단위\")\n",
    "]\n",
    "\n",
    "for separators, description in separators_configs:\n",
    "    print(f\"\\n{description} separators={separators}:\")\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=40,\n",
    "        chunk_overlap=10,\n",
    "        separators=separators\n",
    "    )\n",
    "    chunks = splitter.split_text(test_text)\n",
    "    \n",
    "    for i, chunk in enumerate(chunks, 1):\n",
    "        print(f\"  Chunk {i}: '{chunk.strip()}'\")\n",
    "\n",
    "# ===========================================\n",
    "# chunk_size별 결과 비교\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"chunk_size별 분할 결과 비교\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "chunk_sizes = [50, 100, 150]\n",
    "\n",
    "for size in chunk_sizes:\n",
    "    print(f\"\\nchunk_size={size}:\")\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=size,\n",
    "        chunk_overlap=20,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    "    )\n",
    "    chunks = splitter.split_text(text)\n",
    "    \n",
    "    print(f\"총 {len(chunks)}개 청크 생성\")\n",
    "    avg_length = sum(len(chunk) for chunk in chunks) / len(chunks)\n",
    "    print(f\"평균 청크 길이: {avg_length:.1f}자\")\n",
    "    \n",
    "    for i, chunk in enumerate(chunks, 1):\n",
    "        print(f\"  Chunk {i}: '{chunk.strip()[:30]}...' (길이: {len(chunk)}자)\")\n",
    "\n",
    "# ===========================================\n",
    "# chunk_overlap 효과 확인\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"chunk_overlap 효과 확인\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "overlap_values = [0, 10, 30]\n",
    "\n",
    "for overlap in overlap_values:\n",
    "    print(f\"\\nchunk_overlap={overlap}:\")\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=80,\n",
    "        chunk_overlap=overlap,\n",
    "        separators=[\"\\n\\n\", \".\", \" \"]\n",
    "    )\n",
    "    chunks = splitter.split_text(text)\n",
    "    \n",
    "    print(f\"총 {len(chunks)}개 청크 생성\")\n",
    "    for i, chunk in enumerate(chunks, 1):\n",
    "        print(f\"  Chunk {i}: '{chunk.strip()}'\")\n",
    "        \n",
    "        # 중복 부분 확인\n",
    "        if i > 1 and overlap > 0:\n",
    "            prev_chunk = chunks[i-2].strip()\n",
    "            curr_chunk = chunk.strip()\n",
    "            # 간단한 중복 확인 (마지막 10자와 첫 10자 비교)\n",
    "            if len(prev_chunk) >= 10 and len(curr_chunk) >= 10:\n",
    "                prev_end = prev_chunk[-10:]\n",
    "                curr_start = curr_chunk[:10]\n",
    "                if any(word in curr_start for word in prev_end.split() if len(word) > 2):\n",
    "                    print(f\"    중복 감지: 이전 청크와 겹치는 부분 있음\")\n",
    "\n",
    "# ===========================================\n",
    "# 활용 가이드\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"실무 활용 가이드\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "RecursiveCharacterTextSplitter 사용 가이드:\n",
    "\n",
    "1. 기본 설정 (일반적 문서):\n",
    "   chunk_size=1000, chunk_overlap=200\n",
    "   separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    "\n",
    "2. 한국어 문서 최적화:\n",
    "   chunk_size=500-1000, chunk_overlap=100-200\n",
    "   separators=[\"\\n\\n\", \"\\n\", \".\", \"。\", \" \"]\n",
    "\n",
    "3. 코드 문서:\n",
    "   separators=[\"\\n\\n\", \"\\n\", \"\\t\", \" \"]\n",
    "\n",
    "4. 대화/채팅 로그:\n",
    "   separators=[\"\\n\\n\", \"\\n\", \":\", \" \"]\n",
    "\n",
    "장점:\n",
    "- 의미 단위로 자연스러운 분할\n",
    "- 계층적 구분자로 최적화된 분할점 찾기\n",
    "- 텍스트 특성에 맞는 유연한 설정\n",
    "\n",
    "주의사항:\n",
    "- chunk_size는 LLM 토큰 제한 고려\n",
    "- chunk_overlap은 맥락 보존과 비용의 균형\n",
    "- separators 순서가 분할 품질 결정\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n프로그램 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed4a034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-farQSE-J-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
